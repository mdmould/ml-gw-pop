{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b61cb1f-6b15-46b8-9992-82988a05fdc7",
   "metadata": {},
   "source": [
    "If you're running in a separate notebook (e.g., Google Colab), go through and un-comment the cells below as required. Also make sure to set the runtime before running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee84ca38-867c-4a27-b469-7bb8f11ce30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy matplotlib corner h5ify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5472e1-9d48-4d63-bf1d-64666d1d79b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you're running on CPU:\n",
    "# !pip install jax numypro\n",
    "\n",
    "# # If you're running on GPU\n",
    "# !pip install -U 'jax[cuda12]'\n",
    "# !pip install 'numpyro[cuda]' -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e4b1d2-d637-4780-84d1-d5b7d7e87fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wcosmo jax_tqdm equinox equinox optax flowjax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e039aa-9d5f-4942-bcbd-0cda0937789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download software injections and parameter estimation from LVK O3:\n",
    "# !mkdir -p data\n",
    "# !wget https://github.com/mdmould/ml-gw-pop/blob/main/data/vt.h5 -P data\n",
    "# !wget https://github.com/mdmould/ml-gw-pop/blob/main/data/pe.h5 -P data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b9b25e-4b51-47a7-abda-fb502503bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you're running on a shared cluster and want to limit the resources you take up:\n",
    "# import os\n",
    "# os.environ[\"OPENBLAS_NUM_THREADS\"] = '1'\n",
    "# os.environ[\"MKL_NUM_THREADS\"] = '1'\n",
    "# os.environ[\"VECLIB_MAXIMUM_THREADS\"] = '1'\n",
    "# os.environ[\"NUMEXPR_NUM_THREADS\"] = '1'\n",
    "# os.environ['OMP_NUM_THREADS'] = '1'\n",
    "# os.environ['NPROC'] = '1'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058541e4-5721-4f03-916b-7d6abaaa84ca",
   "metadata": {},
   "source": [
    "## Bonus: Hamiltonian Monte Carlo for gravitational-wave population inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f1ae32-a5cf-4f42-a5d9-011d2910696f",
   "metadata": {},
   "source": [
    "Hamiltonian Monte Carlo is a gradient-based stochastic sampling algorithm. It's particularly useful for sampling from high-dimensional posterior distributions. Here, we'll [numpyro](https://num.pyro.ai/en/latest/mcmc.html) for gravitational-wave population inferece.\n",
    "\n",
    "Most of the code is copied over from the [variational-inference.ipynb](variational-inference.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba92f396-e8d9-4eff-aecd-d954c2e7e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "jax.config.update('jax_enable_x64', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8872384d-c062-4889-9bdc-30841d4dcb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for GPU devices\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d5664f-0f07-49e9-b5f9-3a906589b9b5",
   "metadata": {},
   "source": [
    "We will perform population inference on the catalogue of black-hole mergers with false-alarm rates > 1/year from O3. Below, we load in pre-prepared parameter estimation results for those events and a set of software injections that we can use to estimate selection effects (the scripts in the `data/` folder were used to download and prepare the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8565bc08-9f83-459f-8514-fb93269f9e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5ify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848a34e8-eb3c-4c88-bd9b-2edc8dc5f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "injections = h5ify.load('data/vt.h5')\n",
    "injections = {\n",
    "    k: jnp.array(injections[k], dtype = jnp.float64).squeeze()\n",
    "    for k in injections\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376b92f-b143-4030-a143-69d6975abb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriors = h5ify.load('data/pe.h5')\n",
    "posteriors = {\n",
    "    k: jnp.array([posteriors[event][k] for event in sorted(posteriors)])\n",
    "    for k in posteriors[list(posteriors)[0]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f80b92-9ae0-41c7-be37-559a6feae927",
   "metadata": {},
   "source": [
    "#### Population model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a96f28-7b12-415b-95ae-0b79cdeec071",
   "metadata": {},
   "source": [
    "First, let's define the population model that we'll use to model the astrophysical distribution of sources. We'll include source-frame primary masses, binary mass ratio, dimensionless spin magnitudes, spin-orbit misalignments, and redshift.\n",
    "\n",
    "- The primary masses and mass ratios will follow my version [Power Law + Peak](https://arxiv.org/abs/1801.02699) model, which has tapering functions at low and high black-hole masses with analytical normalization.\n",
    "- Spin magnitudes will be fit with a truncated normal distribution, independent and identical between primary and secondary black holes.\n",
    "- Ditto for spin tilts.\n",
    "- We'll assume that the merger rate evolves over comoving volume and source-frame time as a [power law in redshift](https://arxiv.org/abs/1805.10270).\n",
    "\n",
    "The key thing to remember is that the likelihood function - and thus the population model - *must* be automatically differentiable. To be compatible with the framework here, it must be coded in JAX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a51874-3723-43bf-9f56-8d2ae78d7013",
   "metadata": {},
   "source": [
    "We'll also use [wcosmo](https://github.com/ColmTalbot/wcosmo), which is a nice package for cosmological calculations in JAX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e5a8a5-989d-45d1-9771-588eb9abd4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wcosmo\n",
    "wcosmo.disable_units()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e3d0a2-1390-436b-b5e0-c951a868fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tapering functions\n",
    "\n",
    "def cubic_filter(x):\n",
    "    return (3 - 2 * x) * x**2 * (0 <= x) * (x <= 1) + (1 < x)\n",
    "\n",
    "def highpass(x, xmin, dmin):\n",
    "    return cubic_filter((x - xmin) / dmin)\n",
    "\n",
    "def lowpass(x, xmax, dmax):\n",
    "    return highpass(x, xmax, -dmax)\n",
    "\n",
    "def bandpass(x, xmin, xmax, dmin, dmax):\n",
    "    return highpass(x, xmin, dmin) * lowpass(x, xmax, dmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9609110-ac50-4e59-bbb7-7c214fc299ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# power law functions\n",
    "\n",
    "def powerlaw(x, alpha, xmin, xmax):\n",
    "    cut = (xmin <= x) * (x <= xmax)\n",
    "    shape = x**alpha\n",
    "    norm = (xmax**(alpha + 1) - xmin**(alpha + 1)) / (alpha + 1)\n",
    "    return cut * shape / norm\n",
    "\n",
    "def powerlaw_integral(x, alpha, loc, delta):\n",
    "    a, c, d = alpha, loc, delta\n",
    "    return (\n",
    "        3 * (2 * c + (4 + a) * d)\n",
    "        * (c**2 / (1 + a) - 2 * c * x / (2 + a) + x**2 / (3 + a))\n",
    "        - 2 * (x - c)**3\n",
    "    ) * x**(1 + a) / (4 + a) / d**3\n",
    "\n",
    "def highpass_powerlaw_integral(x, alpha, xmin, xmax, dmin):\n",
    "    return (\n",
    "        (\n",
    "            - powerlaw_integral(xmin, alpha, xmin, dmin)\n",
    "            + powerlaw_integral(jnp.minimum(xmin + dmin, x), alpha, xmin, dmin)\n",
    "        ) * (xmin <= x)\n",
    "        + (\n",
    "            - (xmin + dmin)**(alpha + 1) / (alpha + 1)\n",
    "            + xmax**(alpha + 1) / (alpha + 1)\n",
    "        ) * (xmin + dmin <= x)\n",
    "    )\n",
    "\n",
    "def highpass_powerlaw(x, alpha, xmin, xmax, dmin):\n",
    "    cut = (xmin <= x) * (x <= xmax)\n",
    "    shape = x**alpha * highpass(x, xmin, dmin)\n",
    "    norm = highpass_powerlaw_integral(xmax, alpha, xmin, xmax, dmin)\n",
    "    return cut * shape / norm\n",
    "\n",
    "def bandpass_powerlaw(x, alpha, xmin, xmax, dmin, dmax):\n",
    "    cut = (xmin <= x) * (x <= xmax)\n",
    "    shape = x**alpha * bandpass(x, xmin, xmax, dmin, dmax)\n",
    "    norm = (\n",
    "        - powerlaw_integral(xmin, alpha, xmin, dmin)\n",
    "        + powerlaw_integral(xmin + dmin, alpha, xmin, dmin)\n",
    "        - (xmin + dmin)**(alpha + 1) / (alpha + 1)\n",
    "        + (xmax - dmax)**(alpha + 1) / (alpha + 1)\n",
    "        - powerlaw_integral(xmax - dmax, alpha, xmax, -dmax)\n",
    "        + powerlaw_integral(xmax, alpha, xmax, -dmax)\n",
    "    )\n",
    "    return cut * shape / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee5cacd-b157-425c-b62b-7ed516faeebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian functions\n",
    "\n",
    "def truncnorm(x, mu, sigma, xmin, xmax):\n",
    "    cut = (xmin <= x) * (x <= xmax)\n",
    "    shape = jax.scipy.stats.norm.pdf(x, mu, sigma)\n",
    "    norm = (\n",
    "        - jax.scipy.stats.norm.cdf(xmin, mu, sigma)\n",
    "        + jax.scipy.stats.norm.cdf(xmax, mu, sigma)\n",
    "    )\n",
    "    return cut * shape / norm\n",
    "\n",
    "def normal_integral(x, mu, sigma, loc, delta):\n",
    "    m, s, c, d = mu, sigma, loc, delta\n",
    "    return (\n",
    "        jnp.exp(-(x - m)**2 / 2 / s ** 2) * (2 / jnp.pi)**0.5 * s * (\n",
    "            6 * c * (c + d - m - x)\n",
    "            - 3 * d * (m + x)\n",
    "            + 2 * (m**2 + 2 * s**2 + m * x + x**2)\n",
    "        )\n",
    "        - jax.lax.erf((m - x) / s / 2**0.5) * (\n",
    "            (2 * c + 3 * d - 2 * m) * (c - m)**2\n",
    "            + 3 * s**2 * (2 * c + d - 2 * m)\n",
    "        )\n",
    "    ) / 2 / d**3\n",
    "\n",
    "def bandpass_normal(x, mu, sigma, xmin, xmax, dmin, dmax):\n",
    "    cut = (xmin <= x) * (x <= xmax)\n",
    "    shape = (\n",
    "        jax.scipy.stats.norm.pdf(x, mu, sigma)\n",
    "        * bandpass(x, xmin, xmax, dmin, dmax)\n",
    "    )\n",
    "    norm = (\n",
    "        - normal_integral(xmin, mu, sigma, xmin, dmin)\n",
    "        + normal_integral(xmin + dmin, mu, sigma, xmin, dmin)\n",
    "        - jax.scipy.stats.norm.cdf(xmin + dmin, mu, sigma)\n",
    "        + jax.scipy.stats.norm.cdf(xmax - dmax, mu, sigma)\n",
    "        - normal_integral(xmax - dmax, mu, sigma, xmax, -dmax)\n",
    "        + normal_integral(xmax, mu, sigma, xmax, -dmax)\n",
    "    )\n",
    "    return cut * shape / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf724d-5f74-45f0-ae1e-c37e8c1e35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# primary mass\n",
    "def pdf_m(m, parameters):\n",
    "    pl = bandpass_powerlaw(\n",
    "        m,\n",
    "        parameters['alpha'],\n",
    "        parameters['m_min'],\n",
    "        parameters['m_max'],\n",
    "        parameters['d_min'],\n",
    "        parameters['d_max'],\n",
    "    )\n",
    "    tn = bandpass_normal(\n",
    "        m,\n",
    "        parameters['mu_m'],\n",
    "        parameters['sigma_m'],\n",
    "        parameters['m_min'],\n",
    "        parameters['m_max'],\n",
    "        parameters['d_min'],\n",
    "        parameters['d_max'],\n",
    "    )\n",
    "    return (1 - parameters['f_m']) * pl + parameters['f_m'] * tn\n",
    "\n",
    "# mass ratio - this is a bit of a handful, but otherwise, autodiff doesn't work\n",
    "# let me know if you spot a better way to do it :')\n",
    "def pdf_q_given_m(q, m, parameters):\n",
    "    # pdf defined in terms if secondary mass, then converted to mass ratio\n",
    "    pdf = lambda q, m: highpass_powerlaw(\n",
    "        q * m, parameters['beta'], parameters['m_min'], m, parameters['d_min'],\n",
    "    ) * m\n",
    "    single = lambda q, m: jax.lax.cond(\n",
    "        parameters['m_min'] <= q * m, lambda: pdf(q, m), lambda: 0.0,\n",
    "    )\n",
    "    return jax.vmap(single)(q.ravel(), m.ravel()).reshape(q.shape)\n",
    "\n",
    "# spin magnitude\n",
    "def pdf_a(a, parameters):\n",
    "    return truncnorm(a, parameters['mu_a'], parameters['sigma_a'], 0, 1)\n",
    "\n",
    "# spin tilt\n",
    "def pdf_c(c, parameters):\n",
    "    return truncnorm(c, parameters['mu_c'], parameters['sigma_c'], -1, 1)\n",
    "\n",
    "# redshift\n",
    "def shape_z(z, parameters):\n",
    "    return (1 + z)**parameters['gamma']\n",
    "\n",
    "def pdf_z(z, parameters):\n",
    "    zmax = 2\n",
    "    fn = lambda z: (\n",
    "        shape_z(z, parameters)\n",
    "        * wcosmo.Planck15.differential_comoving_volume(z) * 4 * jnp.pi / 1e9\n",
    "    )\n",
    "    cut = (0 < z) * (z <= zmax)\n",
    "    shape = fn(z)\n",
    "    zz = jnp.linspace(0, zmax, 10_000)\n",
    "    norm = jnp.trapezoid(fn(zz), zz)\n",
    "    return cut * shape / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adbc36f-1a8b-410f-9a1a-73ffd54c9bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the combined probability density\n",
    "def density(data, parameters):\n",
    "    return (\n",
    "        pdf_m(data['mass_1_source'], parameters)\n",
    "        * pdf_q_given_m(data['mass_ratio'], data['mass_1_source'], parameters)\n",
    "        # * pdf_q(data['mass_ratio'], parameters)\n",
    "        * pdf_a(data['a_1'], parameters)\n",
    "        * pdf_a(data['a_2'], parameters)\n",
    "        * pdf_c(data['cos_tilt_1'], parameters)\n",
    "        * pdf_c(data['cos_tilt_2'], parameters)\n",
    "        * pdf_z(data['redshift'], parameters)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedd26ac-4345-425f-bc7d-eba6dd7f910a",
   "metadata": {},
   "source": [
    "#### Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e2a4e-b749-43f3-bbd3-fbe6c5d31fea",
   "metadata": {},
   "source": [
    "Next, we'll set priors on the parameters of the population model - these are the parameters we want to measure from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ff81a2-9534-46a3-b29a-b9e0a239fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06d8b8b-e3ca-4d67-97e2-ea68100f6d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = dict(\n",
    "    alpha = numpyro.distributions.Uniform(-10, 10),\n",
    "    m_min = numpyro.distributions.Uniform(2, 6),\n",
    "    m_max = numpyro.distributions.Uniform(70, 100),\n",
    "    d_min = numpyro.distributions.Uniform(0, 10),\n",
    "    d_max = numpyro.distributions.Uniform(0, 10),\n",
    "    mu_m = numpyro.distributions.Uniform(20, 50),\n",
    "    sigma_m = numpyro.distributions.Uniform(1, 10),\n",
    "    f_m = numpyro.distributions.Uniform(0, 1),\n",
    "    beta = numpyro.distributions.Uniform(-10, 10),\n",
    "    mu_a = numpyro.distributions.Uniform(0, 1),\n",
    "    sigma_a = numpyro.distributions.Uniform(0.1, 1),\n",
    "    mu_c = numpyro.distributions.Uniform(-1, 1),\n",
    "    sigma_c = numpyro.distributions.Uniform(0.1, 4),\n",
    "    gamma = numpyro.distributions.Uniform(-10, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b83f6db-cc21-4964-9afe-6c311eea8515",
   "metadata": {},
   "source": [
    "#### Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bbd1d0-06e6-4808-abcb-95a2e6992979",
   "metadata": {},
   "source": [
    "How likely is it that our population model is responsible for the observed data?\n",
    "\n",
    "Below we code up the gravitational-wave population likelihood; see, e.g.,\n",
    "\n",
    "- https://arxiv.org/abs/1809.02063,\n",
    "- https://arxiv.org/abs/2007.05579,\n",
    "- https://arxiv.org/abs/2410.19145.\n",
    "\n",
    "In particular, the likelihood function is approximated with several Monte Carlo integrals, which introduces additional statistical variance (https://arxiv.org/abs/1904.10879, https://arxiv.org/abs/2204.00461, https://arxiv.org/abs/2304.06138). We make sure to keep track of this variance below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f161c-9343-42d1-925a-3e9df236c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and variance of the mean\n",
    "def mean_and_variance(weights, n):\n",
    "    mean = jnp.sum(weights, axis = -1) / n\n",
    "    variance = jnp.sum(weights**2, axis = -1) / n**2 - mean**2 / n\n",
    "    return mean, variance\n",
    "\n",
    "# lazy ln(mean) and variance of ln(mean)\n",
    "def ln_mean_and_variance(weights, n):\n",
    "    mean, variance = mean_and_variance(weights, n)\n",
    "    return jnp.log(mean), variance / mean**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6261fb-26ef-4cff-a7e1-ec0a45d0d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln_likelihood_and_variance(posteriors, injections, density, parameters):\n",
    "    pe_weights = density(posteriors, parameters) / posteriors['prior']\n",
    "    vt_weights = density(injections, parameters) / injections['prior']\n",
    "    num_obs, num_pe = pe_weights.shape\n",
    "    ln_lkls, pe_variances = ln_mean_and_variance(pe_weights, num_pe)\n",
    "    ln_pdet, vt_variance = ln_mean_and_variance(vt_weights, injections['total'])\n",
    "    ln_lkl = ln_lkls.sum() - ln_pdet * num_obs\n",
    "    variance = pe_variances.sum() + vt_variance * num_obs**2\n",
    "    # ln_lkl = jnp.nan_to_num(ln_lkl, nan = -jnp.inf)\n",
    "    # variance = jnp.nan_to_num(variance, nan = jnp.inf)\n",
    "    return ln_lkl, variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f798da-9a43-4fa7-b655-30db2ab033ef",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e209be7d-2d43-448b-872e-4f6a9d354b12",
   "metadata": {},
   "source": [
    "Now we'll draw samples from the posterior distributions using Hamiltonian Monte Carlo in [numpyro](https://num.pyro.ai/en/latest/mcmc.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f20c56-8b12-42b9-aeb1-8de5c921c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_reparam(name, dist, **args):\n",
    "    base = numpyro.distributions.Normal()\n",
    "    z = numpyro.sample(f'_{name}', base, **args)\n",
    "    return numpyro.deterministic(name, dist.icdf(base.cdf(z)))\n",
    "\n",
    "def sample_priors(priors, reparam = False):\n",
    "    if reparam:\n",
    "        return {k: sample_reparam(k, priors[k]) for k in priors}\n",
    "    return {k: numpyro.sample(k, priors[k]) for k in priors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e631f4e-465e-45a6-b620-c247b97c1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpyro_model(posteriors, injections, density, priors, reparam = False):\n",
    "    parameters = sample_priors(priors, reparam)\n",
    "    ln_likelihood, variance = ln_likelihood_and_variance(\n",
    "        posteriors, injections, density, parameters,\n",
    "    )\n",
    "    numpyro.deterministic('ln_likelihood', ln_likelihood)\n",
    "    numpyro.deterministic('variance', variance)\n",
    "    numpyro.factor('factor', ln_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dd77d0-a5a2-4e87-b9b5-ceec0bb73d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts = numpyro.infer.NUTS(numpyro_model)\n",
    "mcmc = numpyro.infer.MCMC(nuts, num_warmup = 1_000, num_samples = 1_000)\n",
    "mcmc.run(jax.random.key(0), posteriors, injections, density, priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35db3c3-d53a-439a-ab9f-153a09fd869f",
   "metadata": {},
   "source": [
    "Below shows some summary statistics to check that the MCMC chain converged or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a3d62a-adc5-4ff5-b2de-caf7cbbe373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyro.diagnostics.print_summary(mcmc.get_samples(), group_by_chain = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fe98f0-0599-401e-9504-0fd9154ce4da",
   "metadata": {},
   "source": [
    "Let's also check the Monte Carlo variance to see how trustworthy our estimate of the population likelihood is over the posterior samples we drew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3c46b7-f3af-4a36-98e9-1bf4ccd7323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d00fbc0-02b6-4cf3-ac9c-162226cfb0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mcmc.get_samples()['variance'], bins = 100);\n",
    "plt.axvline(1, c = 'r');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fec98c-74cd-46f6-aeb2-90b4b4c4da6e",
   "metadata": {},
   "source": [
    "Then let's look at the posterior distribution itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f620b9d-d7d7-4a06-96a5-677ee8ad8578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from corner import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c7c3d-d25a-42cd-b472-693a2dd7c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut = mcmc.get_samples()['variance'] < 1\n",
    "cut = slice(None)\n",
    "posterior = {k: mcmc.get_samples()[k][cut] for k in priors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9c0235-2b20-49da-af83-6d65ddaa774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corner(np.transpose(list(posterior.values())), labels = list(priors));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608273ad-afb9-443a-83ba-59a09c5109c4",
   "metadata": {},
   "source": [
    "And finally, the inferred population-level distributiona of source parameters and their posterior uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe9bd5d-47c4-452d-895c-88f2b1cb5d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = dict(\n",
    "    mass_1_source = jnp.linspace(2, 100, 1_000),\n",
    "    mass_ratio = jnp.linspace(0, 1, 1_000),\n",
    "    a = jnp.linspace(0, 1, 1_000),\n",
    "    cos_tilt = jnp.linspace(-1, 1, 1_000),\n",
    "    redshift = jnp.linspace(0, 2, 1_000),\n",
    ")\n",
    "\n",
    "# the mass ratio model is conditional on the primary mass, so we have to marginalize\n",
    "def pdf_q_marginal(q, parameters):\n",
    "    x, y = jnp.meshgrid(q, grid['mass_1_source'], indexing = 'ij')\n",
    "    p = pdf_q_given_m(x, y, parameters) * pdf_m(y, parameters)\n",
    "    return jnp.trapezoid(p, y, axis = 1)\n",
    "\n",
    "pdf = dict(\n",
    "    mass_1_source = pdf_m,\n",
    "    mass_ratio = pdf_q_marginal,\n",
    "    a = pdf_a,\n",
    "    cos_tilt = pdf_c,\n",
    "    redshift = pdf_z,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1551e8c9-c2c3-4c15-9a56-b1ea0cdbfc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(k, data):\n",
    "    # we use sequential map for mass ratio because the integral uses more memory\n",
    "    single = lambda parameters: pdf[k](grid[k], parameters)\n",
    "    if k == 'mass_ratio':\n",
    "        ps = jax.lax.map(single, data)\n",
    "    else:\n",
    "        ps = jax.vmap(single)(data)\n",
    "\n",
    "    for qs, alpha in (\n",
    "        ((0.005, 0.995), 0.2),\n",
    "        ((0.05, 0.95), 0.3),\n",
    "        ((0.25, 0.75), 0.4),\n",
    "    ):\n",
    "        label = f'{(qs[1]-qs[0]) * 100:.0f}% posterior'\n",
    "        plt.fill_between(\n",
    "            grid[k], *np.quantile(ps, qs, axis = 0), label = label,\n",
    "            color = 'C0', alpha = alpha, lw = 0,\n",
    "        )\n",
    "\n",
    "    plt.plot(\n",
    "        grid[k], np.median(ps, axis = 0), label = 'median posterior',\n",
    "        c = 'C1', lw = 2,\n",
    "    )\n",
    "    plt.plot(\n",
    "        grid[k], np.mean(ps, axis = 0), label = 'mean posterior (PPD)',\n",
    "        c = 'C2', lw = 2, ls = '--',\n",
    "    )\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel(k)\n",
    "    plt.ylabel(f'p({k})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7659411-4e50-4309-abde-f22af663ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in 'mass_1_source', 'mass_ratio', 'a', 'cos_tilt', 'redshift':\n",
    "    make_plot(k, posterior)\n",
    "\n",
    "    if k == 'mass_1_source':\n",
    "        plt.semilogy()\n",
    "        plt.ylim(1e-5, 1e0)\n",
    "    elif k == 'mass_ratio':\n",
    "        plt.semilogy()\n",
    "        plt.ylim(1e-2, 1e1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe8e2cf-493a-4db6-a7c1-7c9f62479ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
